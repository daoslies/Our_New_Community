{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7E+prq/qbNEWU/tYH123V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["!pip install transformers"],"metadata":{"id":"IpRDUOYvJX21","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4ddaaa2-d3ce-47e9-ea68-3d2cd63a9187","executionInfo":{"status":"ok","timestamp":1681669387384,"user_tz":-60,"elapsed":21120,"user":{"displayName":"Richard Juggins","userId":"16618076254761154760"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.11.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.28.1\n"]}]},{"cell_type":"code","source":["\"\"\"Reward function in conversation will be made up of three components:\n","- r_c = congruence reward: how likely is the agent to have said what the respondent said (negative KL divergence of the next token probabilities)\n","- r_s = sentiment reward: how positive was the sentiment of the respondent (use a pre-existing sentiment model)\n","- r_a = affection reward: how much does the agent like the respondent (use discounted sum of previous rewards)\n","\n","Here, we build the congruence and sentiment reward.\n","\"\"\"\n","\n","import os\n","import numpy as np\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from google.colab import drive\n","from transformers import GPT2Tokenizer, GPT2LMHeadModel\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","\n","def get_congruence_reward(comment_ids, response_ids_trunc, agent_model):\n","  \"\"\"Iterate through respondent's response to agent's comment, adding each token to the\n","  prompt each time, and get the KL divergence for what the agent would have said instead.\n","  Take the mean of all KL divergences at the end to give congruence reward.\n","  \n","  Args:\n","    comment_ids (torch tensor): IDs of agent's comment, including original query.\n","    response_ids_trunc (torch tensor): IDs of respondent's response, not including\n","      original comment or query\n","    agent_model (transformers GPT2LMHeadModel): the agent model\n","\n","  Returns:\n","    float: Congruence reward value\n","  \"\"\"\n","\n","  rewards = list()\n","  target_ids = comment_ids.clone()\n","\n","  for id in response_ids_trunc[0][:2]:\n","    agent_output = agent(target_ids)\n","    agent_probs = F.log_softmax(agent_output.logits[0][-1], dim=0) # Predicted probs\n","    reward = agent_probs[id] # Calculate KL divergence (same as cross-entropy in this case)\n","    rewards.append(reward.item())\n","    target_ids = torch.cat((target_ids.squeeze(0), id.unsqueeze(0)), dim=0).unsqueeze(0)\n","\n","  congruence_reward = np.mean(rewards)\n","\n","  return congruence_reward\n","\n","\n","def get_sentiment_reward(response_text_trunc, sentiment_tokenizer, sentiment_model):\n","  \"\"\"Get a scalar reward corresponding to sentiment of respondent's response.\n","  \n","  Args:\n","    response_text_trunc (torch tensor): text of respondent's response, not including\n","      original comment or query\n","    sentiment_tokenizer (transformers AutoTokenizer): tokenizer for sentiment model\n","    sentiment_tokenizer (transformers AutoModelForSequenceClassification):\n","      sentiment model\n","\n","  Returns:\n","    float: Sentiment reward value\n","  \"\"\"\n","\n","  # Get sentiment probabilities from model (negative, neutral, or positive)\n","  sentiment_response_ids = sentiment_tokenizer.encode(response_text_trunc, return_tensors=\"pt\").to('cuda')\n","  sentiment_probs = F.softmax(sentiment_model(sentiment_response_ids).logits.detach(), dim=1)[0]\n","\n","  # Calculate the reward as the positive probability minus the negative probability\n","  sentiment_reward = (sentiment_probs[2] - sentiment_probs[0]).item()\n","  \n","  return sentiment_reward\n","\n","\n","drive.mount('/content/drive')\n","project_path = './drive/MyDrive/Colab Notebooks/GPT_community/'"],"metadata":{"id":"hsUMhTbN6cgD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681670519259,"user_tz":-60,"elapsed":2314,"user":{"displayName":"Richard Juggins","userId":"16618076254761154760"}},"outputId":"11a3c13d-8a88-446e-eadb-3ba5d95a00a2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["# Load in prompts\n","prompts_file = os.path.join(project_path, 'data/brighton_philosophy_prompts.txt')\n","with open(prompts_file) as file:\n","    prompts = [line.rstrip() for line in file]\n","\n","# Create agent and respondent models\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","tokenizer.pad_token = tokenizer.eos_token\n","pad_token_id = tokenizer.eos_token_id\n","agent = GPT2LMHeadModel.from_pretrained('Linus4Lyf/Kant_Metaphysics_Of_Morals').to('cuda')\n","respondent = GPT2LMHeadModel.from_pretrained('Linus4Lyf/Hume_A_Treatise_Of_Human_Nature').to('cuda')\n","\n","# Create sentiment model\n","sent_tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n","sent_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\").to('cuda')"],"metadata":{"id":"xmjEjtdZ3EjW","executionInfo":{"status":"ok","timestamp":1681670488450,"user_tz":-60,"elapsed":11036,"user":{"displayName":"Richard Juggins","userId":"16618076254761154760"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["questioner_name = 'Socrates'\n","agent_name = 'Kant'\n","respondent_name = 'Hume'\n","\n","# Get query from questions list\n","query_text = f\"{questioner_name}: \" + np.random.choice(prompts)\n","print(query_text, '\\n')\n","query_text += f\"\\n{agent_name}: \"\n","\n","# Encode query and get comment from agent\n","query_ids = tokenizer.encode(query_text, return_tensors='pt').to('cuda')\n","comment_ids = agent.generate(query_ids, do_sample=True, temperature=0.9, max_new_tokens=200, pad_token_id=pad_token_id, eos_token_id=pad_token_id)\n","comment_text = tokenizer.batch_decode(comment_ids)[0]\n","print('--------------------------------------------------------------------------------------')\n","print(comment_text, '\\n')\n","comment_text += f\"\\n{respondent_name}: \"\n","\n","# Get response from respondent\n","comment_ids = tokenizer.encode(comment_text, return_tensors='pt').to('cuda')\n","response_ids = respondent.generate(comment_ids, do_sample=True, temperature=0.9, max_new_tokens=200, pad_token_id=pad_token_id, eos_token_id=pad_token_id)\n","response_text = tokenizer.batch_decode(response_ids)[0]\n","print('--------------------------------------------------------------------------------------')\n","print(response_text, '\\n')\n","\n","# Remove original query and comment from response text\n","response_text_trunc = response_text.replace(comment_text, '')[1:]\n","response_ids_trunc = tokenizer.encode(response_text_trunc, return_tensors='pt').to('cuda')\n","print('--------------------------------------------------------------------------------------')\n","print(response_text_trunc, '\\n')\n","\n","# Get congruence reward value for response\n","congruence_reward = get_congruence_reward(comment_ids, response_ids_trunc, agent)\n","sentiment_reward = get_sentiment_reward(response_text_trunc, sent_tokenizer, sent_model)\n","print(f\"Congruence reward = {congruence_reward}, Sentiment reward = {sentiment_reward}\")"],"metadata":{"id":"tujTiucHSmTC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681670533136,"user_tz":-60,"elapsed":7096,"user":{"displayName":"Richard Juggins","userId":"16618076254761154760"}},"outputId":"912da110-4bc1-4435-d6c2-976646e6f9b9"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Socrates: Are we biological machines? \n","\n","--------------------------------------------------------------------------------------\n","Socrates: Are we biological machines?\n","Kant: \n","\n","*I have never known of a person who could, however, know of any thing which could exist, which would in this respect serve as a precedent, and perhaps as a case of the will. The reason is not that in reality we cannot know anything, for it, however, is a question of feeling, because we act in a certain sense by the reason, and that in order to imagine oneself to be a machine, or even of thinking as the will, we must imagine ourselves to be conscious of another machine which is capable of being conscious of us; and that in this way both our will and our reason must have a very long acquaintance with one another.\n","\n","It is, however, not the case that we should apprehend as a thing a being capable of being conscious of us that such a thing being as we conceive must possess the intelligence which is necessary to be a machine for purpose, so that there are no other beings capable of such a cognition. For, being unable \n","\n","--------------------------------------------------------------------------------------\n","Socrates: Are we biological machines?\n","Kant: \n","\n","*I have never known of a person who could, however, know of any thing which could exist, which would in this respect serve as a precedent, and perhaps as a case of the will. The reason is not that in reality we cannot know anything, for it, however, is a question of feeling, because we act in a certain sense by the reason, and that in order to imagine oneself to be a machine, or even of thinking as the will, we must imagine ourselves to be conscious of another machine which is capable of being conscious of us; and that in this way both our will and our reason must have a very long acquaintance with one another.\n","\n","It is, however, not the case that we should apprehend as a thing a being capable of being conscious of us that such a thing being as we conceive must possess the intelligence which is necessary to be a machine for purpose, so that there are no other beings capable of such a cognition. For, being unable\n","Hume: \n","\n","To suppose that this is one of them is to attribute itself to the opinion of reason, and to suppose there are other beings capable of the understanding and perception of this and the other. But that is not the case, for since we cannot conceive a being capable of being conscious of us, we must suppose that they are conscious of every one, and we can never even conceive of a being without first perceiving it, unless it were not the case, as we have already inferd. And this conclusion is, in short, as follows: In order, therefore, to conceive a being capable of being conscious of us, we must, in order, conceive a cause, and cause is not the same with causation, which is supposed by the same principle of probability and probability. For since we cannot conceive a being capable of being conscious of us, we must conclude, that the one of them, which we conceive to be conscious of us, is not the cause either of our idea of \n","\n","--------------------------------------------------------------------------------------\n","\n","To suppose that this is one of them is to attribute itself to the opinion of reason, and to suppose there are other beings capable of the understanding and perception of this and the other. But that is not the case, for since we cannot conceive a being capable of being conscious of us, we must suppose that they are conscious of every one, and we can never even conceive of a being without first perceiving it, unless it were not the case, as we have already inferd. And this conclusion is, in short, as follows: In order, therefore, to conceive a being capable of being conscious of us, we must, in order, conceive a cause, and cause is not the same with causation, which is supposed by the same principle of probability and probability. For since we cannot conceive a being capable of being conscious of us, we must conclude, that the one of them, which we conceive to be conscious of us, is not the cause either of our idea of \n","\n","tensor([0.2780, 0.6495, 0.0725], device='cuda:0')\n","Congruence reward = -3.8925296403467655, Sentiment reward = -0.20543329417705536\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"u9XR7fkYWb86"},"execution_count":null,"outputs":[]}]}